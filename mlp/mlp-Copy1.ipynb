{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "50336115-afe7-40c4-8f7c-cf89b85171ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import random\n",
    "from keras import Input\n",
    "from keras.layers import Dropout\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "05a85386-34d1-4b9c-9aca-f02054a2fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv('../datos_simulados/datos_final.csv')\n",
    "# Variables categóricas importantes\n",
    "#columnas_categoricas = ['Clase', 'Pieza', 'Superficie_1', 'Superficie_2', 'Estado_cavidad', 'Tecnica']\n",
    "columnas_categoricas = ['Clase', 'Pieza', 'Superficie_1', 'Superficie_2', 'Tecnica']\n",
    "# Variables numéricas relevantes\n",
    "columnas_numericas = ['Tamanio_cavidad_mm', 'Indice_contraccion_%', 'Margen_cavo_mm']\n",
    "\n",
    "# Codificar variables categóricas\n",
    "df_codificado = pd.get_dummies(df[columnas_categoricas + columnas_numericas])\n",
    "\n",
    "# Definir X (entradas) e y (salida)\n",
    "X = df_codificado\n",
    "y = df['Peso_resina_inicial_mg'] - df['Peso_sobrante_mg']\n",
    "\n",
    "# Dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "de590ac9-dee2-4239-a8a0-802cfd72f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar características con StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6fe993f0-e571-4ced-b89b-f21ed8d1609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo secuencial\n",
    "modelo_mlp = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])  # salida para regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7fc3a7-04d6-452a-af31-328e30c5746d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - loss: 2197.9241 - mae: 33.3491 - val_loss: 262.1385 - val_mae: 13.6663\n",
      "Epoch 2/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 711us/step - loss: 263.5393 - mae: 13.6193 - val_loss: 264.0851 - val_mae: 13.7257\n",
      "Epoch 3/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - loss: 259.6660 - mae: 13.5473 - val_loss: 265.3530 - val_mae: 13.6948\n",
      "Epoch 4/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 788us/step - loss: 253.9429 - mae: 13.3483 - val_loss: 272.5323 - val_mae: 13.7591\n",
      "Epoch 5/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - loss: 259.4663 - mae: 13.5388 - val_loss: 260.8682 - val_mae: 13.6400\n",
      "Epoch 6/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 256.3923 - mae: 13.4559 - val_loss: 260.5898 - val_mae: 13.6930\n",
      "Epoch 7/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738us/step - loss: 257.9910 - mae: 13.4661 - val_loss: 262.3890 - val_mae: 13.6444\n",
      "Epoch 8/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 676us/step - loss: 257.3615 - mae: 13.5011 - val_loss: 259.5949 - val_mae: 13.6481\n",
      "Epoch 9/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 255.8144 - mae: 13.4576 - val_loss: 261.4929 - val_mae: 13.5992\n",
      "Epoch 10/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682us/step - loss: 255.1299 - mae: 13.4005 - val_loss: 267.5881 - val_mae: 13.7993\n",
      "Epoch 11/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - loss: 257.5013 - mae: 13.5011 - val_loss: 260.3192 - val_mae: 13.6767\n",
      "Epoch 12/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 253.2546 - mae: 13.3567 - val_loss: 278.6575 - val_mae: 13.8709\n",
      "Epoch 13/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721us/step - loss: 253.8849 - mae: 13.3984 - val_loss: 266.0867 - val_mae: 13.7135\n",
      "Epoch 14/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 256.7827 - mae: 13.5159 - val_loss: 261.2572 - val_mae: 13.6749\n",
      "Epoch 15/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 256.5255 - mae: 13.4663 - val_loss: 265.2885 - val_mae: 13.7597\n",
      "Epoch 16/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - loss: 255.3817 - mae: 13.4448 - val_loss: 267.8821 - val_mae: 13.7505\n",
      "Epoch 17/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 250.7011 - mae: 13.2811 - val_loss: 262.1770 - val_mae: 13.6904\n",
      "Epoch 18/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 250.8208 - mae: 13.3794 - val_loss: 261.8718 - val_mae: 13.7568\n",
      "Epoch 19/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - loss: 252.7669 - mae: 13.3594 - val_loss: 258.4001 - val_mae: 13.5644\n",
      "Epoch 20/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - loss: 250.0874 - mae: 13.2447 - val_loss: 261.2846 - val_mae: 13.6695\n",
      "Epoch 21/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 607us/step - loss: 254.6317 - mae: 13.4105 - val_loss: 258.9503 - val_mae: 13.5897\n",
      "Epoch 22/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - loss: 256.7185 - mae: 13.4932 - val_loss: 269.9368 - val_mae: 13.7582\n",
      "Epoch 23/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 249.8489 - mae: 13.2986 - val_loss: 260.9688 - val_mae: 13.6850\n",
      "Epoch 24/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 254.7186 - mae: 13.4056 - val_loss: 260.5754 - val_mae: 13.6644\n",
      "Epoch 25/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - loss: 251.9058 - mae: 13.3350 - val_loss: 259.5653 - val_mae: 13.6594\n",
      "Epoch 26/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 256.0293 - mae: 13.5081 - val_loss: 259.4911 - val_mae: 13.6483\n",
      "Epoch 27/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 600us/step - loss: 252.3331 - mae: 13.3733 - val_loss: 263.4150 - val_mae: 13.7488\n",
      "Epoch 28/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - loss: 253.4886 - mae: 13.3335 - val_loss: 264.1701 - val_mae: 13.7327\n",
      "Epoch 29/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - loss: 255.0440 - mae: 13.4310 - val_loss: 265.4291 - val_mae: 13.7434\n",
      "Epoch 30/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - loss: 251.2617 - mae: 13.3400 - val_loss: 263.3486 - val_mae: 13.7485\n",
      "Epoch 31/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 731us/step - loss: 251.1319 - mae: 13.3042 - val_loss: 260.8453 - val_mae: 13.6705\n",
      "Epoch 32/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 252.0737 - mae: 13.3693 - val_loss: 260.5652 - val_mae: 13.6605\n",
      "Epoch 33/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 660us/step - loss: 254.3124 - mae: 13.3995 - val_loss: 275.7018 - val_mae: 14.0545\n",
      "Epoch 34/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 691us/step - loss: 254.1114 - mae: 13.3865 - val_loss: 267.0893 - val_mae: 13.8287\n",
      "Epoch 35/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 602us/step - loss: 250.2356 - mae: 13.2904 - val_loss: 262.1775 - val_mae: 13.7023\n",
      "Epoch 36/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 680us/step - loss: 256.2141 - mae: 13.4680 - val_loss: 258.2410 - val_mae: 13.5925\n",
      "Epoch 37/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 689us/step - loss: 252.4964 - mae: 13.3383 - val_loss: 263.5212 - val_mae: 13.7535\n",
      "Epoch 38/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 252.1200 - mae: 13.4072 - val_loss: 264.9063 - val_mae: 13.7779\n",
      "Epoch 39/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 695us/step - loss: 252.3821 - mae: 13.3610 - val_loss: 266.3774 - val_mae: 13.7931\n",
      "Epoch 40/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 652us/step - loss: 254.7448 - mae: 13.4147 - val_loss: 259.9655 - val_mae: 13.6078\n",
      "Epoch 41/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 250.9885 - mae: 13.3081 - val_loss: 270.2046 - val_mae: 13.9260\n",
      "Epoch 42/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 688us/step - loss: 253.9848 - mae: 13.4172 - val_loss: 273.5453 - val_mae: 13.8765\n",
      "Epoch 43/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 677us/step - loss: 257.9502 - mae: 13.5121 - val_loss: 261.8831 - val_mae: 13.7029\n",
      "Epoch 44/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - loss: 253.3169 - mae: 13.3868 - val_loss: 263.7047 - val_mae: 13.7445\n",
      "Epoch 45/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 720us/step - loss: 251.7021 - mae: 13.3351 - val_loss: 278.9488 - val_mae: 13.8654\n",
      "Epoch 46/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 684us/step - loss: 251.9103 - mae: 13.3236 - val_loss: 274.4094 - val_mae: 13.9971\n",
      "Epoch 47/150\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 613us/step - loss: 251.8282 - mae: 13.3378 - val_loss: 257.9038 - val_mae: 13.5853\n",
      "Epoch 48/150\n",
      "\u001b[1m397/744\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 256.0798 - mae: 13.4300"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, min_lr=1e-6)\n",
    "\n",
    "# EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Compilar\n",
    "modelo_mlp.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Entrenar\n",
    "historial = modelo_mlp.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=150,\n",
    "    batch_size=16,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    #callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c13b1a-432f-4280-9156-5590145860d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_mse, test_mae = modelo_mlp.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"MAE en prueba: {test_mae:.2f}\")\n",
    "print(f\"MSE en prueba: {test_mse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b741b-93fd-4ac8-a85d-7e9747a91ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperar la pérdida por época durante el entrenamiento\n",
    "train_loss_history = historial.history['loss']\n",
    "epochs = range(len(train_loss_history))\n",
    "\n",
    "# Gráfica general de pérdida\n",
    "plt.plot(epochs, train_loss_history, 'r')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.legend([\"Loss\"])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a14e7-51a3-4981-86a9-f7d184004779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom a partir de la época 20\n",
    "zoomed_loss = train_loss_history[20:]\n",
    "zoomed_epochs = range(20, len(train_loss_history))\n",
    "\n",
    "plt.plot(zoomed_epochs, zoomed_loss)\n",
    "plt.title(\"Zoomed Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919ebc6-a0f2-438f-96ea-3256ccdf9371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones sobre el conjunto de prueba\n",
    "y_pred = modelo_mlp.predict(X_test_scaled)\n",
    "\n",
    "# Calcular RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Calcular R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3de84-249c-4725-bd9d-b76799f539c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la media del valor real de la resina inicial\n",
    "media_real = df[\"Peso_resina_inicial_mg\"].mean()\n",
    "\n",
    "# RMSE obtenido tras evaluación del modelo\n",
    "rmse = rmse  # Sustituye por el valor real si cambia\n",
    "\n",
    "# Calcular el error relativo porcentual\n",
    "error_relativo_pct = (rmse / media_real) * 100\n",
    "precision_aproximada = 100 - error_relativo_pct\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Media real de peso de resina inicial: {media_real:.2f} mg\")\n",
    "print(f\"RMSE: {rmse:.2f} mg\")\n",
    "print(f\"Error relativo aproximado: {error_relativo_pct:.2f} %\")\n",
    "print(f\"Precisión aproximada del modelo: {precision_aproximada:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f622597f-8712-46c2-83db-c7380b8815ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de índice de contracción\n",
    "indice_contraccion = {\n",
    "    \"Compuesta\": 2.0,\n",
    "    \"Fluida\": 3.5,\n",
    "    \"Con fibra de vidrio\": 1.0,\n",
    "    \"Bulk\": 1.5\n",
    "}\n",
    "\n",
    "# Configuraciones posibles\n",
    "tecnicas = [\"Bulk\", \"Estratificacion\"]\n",
    "tipos_resina = list(indice_contraccion.keys())\n",
    "ajustes_margen = [\"Sobreobturado\", \"Subobturado\", \"Equiobturado\"]\n",
    "estados_cavidad = [\"con_tejido\", \"limpia\"]\n",
    "\n",
    "# Leer combinaciones base\n",
    "df_base = pd.read_excel(\"../datos_simulados/Combinaciones.xlsx\")\n",
    "\n",
    "# Lista para una combinación por fila\n",
    "combinaciones_X = []\n",
    "\n",
    "for _, fila in df_base.iterrows():\n",
    "    tecnica = random.choice(tecnicas)\n",
    "    tipo_resina = random.choice(tipos_resina)\n",
    "    indice = indice_contraccion[tipo_resina]\n",
    "\n",
    "    tam = round(random.uniform(fila['Tam_min'], fila['Tam_max']), 2)\n",
    "\n",
    "    ajuste = random.choice(ajustes_margen)\n",
    "    if ajuste == \"Equiobturado\":\n",
    "        margen = round(random.uniform(tam - 0.2, tam + 0.2), 2)\n",
    "    elif ajuste == \"Sobreobturado\":\n",
    "        margen = round(random.uniform(tam + 0.01, tam + 1.0), 2)\n",
    "    else:\n",
    "        margen = round(random.uniform(max(0.1, tam - 1.0), tam - 0.01), 2)\n",
    "\n",
    "    combinaciones_X.append({\n",
    "        \"Clase\": fila[\"Clase\"],\n",
    "        \"Pieza\": fila[\"Pieza\"],\n",
    "        \"Superficie_1\": fila[\"Superficie_1\"],\n",
    "        \"Superficie_2\": fila[\"Superficie_2\"],\n",
    "        \"Estado_cavidad\": random.choice(estados_cavidad),\n",
    "        \"Tecnica\": tecnica,\n",
    "        \"Tamanio_cavidad_mm\": tam,\n",
    "        \"Indice_contraccion_%\": indice,\n",
    "        \"Margen_cavo_mm\": margen\n",
    "    })\n",
    "\n",
    "# Crear DataFrame con combinaciones generadas\n",
    "df_combos = pd.DataFrame(combinaciones_X)\n",
    "\n",
    "# Codificar y alinear columnas como en el entrenamiento\n",
    "df_combos_codificado = pd.get_dummies(df_combos)\n",
    "df_combos_codificado = df_combos_codificado.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "# Aplicar el mismo escalado\n",
    "df_combos_scaled = scaler.transform(df_combos_codificado)\n",
    "\n",
    "# Predecir la resina inicial\n",
    "resina_recomendada = modelo_mlp.predict(df_combos_scaled)\n",
    "\n",
    "# Mostrar resultados\n",
    "for i, valor in enumerate(resina_recomendada.flatten(), start=1):\n",
    "    datos = df_combos.loc[i - 1]\n",
    "    print(f\"Combinación {i} → {valor:.2f} mg | Cavidad: {datos['Tamanio_cavidad_mm']} mm | Clase: {datos['Clase']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
